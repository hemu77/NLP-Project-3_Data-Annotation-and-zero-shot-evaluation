{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Annotaion and Analysis of Fine-tuned dehatebert-mono-english model on the Uncleaned and Cleaned data of the hatespeech"
      ],
      "metadata": {
        "id": "qQsvLqbU3wE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I have annotated the data based on the annotation guidelines attached in my repository .let's start with how i collected the data"
      ],
      "metadata": {
        "id": "JRCEjtKs4sSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Collection:\n",
        "the data is collected from a large corpus from the kaggle :https://www.kaggle.com/datasets/elgringofrances/english-hate-speech-superset?select=en_hf_102024.csv.          This is a 70mb dataset consisting of the content from any sources. I have searched for the 'twitter' label and retreived the good 150 columns consisting of nearly equal '0' and '1'labels,ensuring the perfect rate of data sampling and named the file as **tweets.xlsx** . I have colleced 0 label first and then 1 .so, i'm shuffling the **tweets.xlsx** file such that the data will be good for the labelling."
      ],
      "metadata": {
        "id": "1CBJxzSBrVO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the Excel file\n",
        "df = pd.read_excel('tweets.xlsx')\n",
        "\n",
        "# Shuffle the rows randomly\n",
        "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save the shuffled dataset to a new Excel file\n",
        "shuffled_df.to_excel('final_tweets.xlsx', index=False)\n",
        "\n",
        "print(\"Dataset shuffled and saved as 'final_tweets.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "Z4U1Tt8IcC3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070800f3-2075-4248-a6c9-0f20ae912c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shuffled and saved as 'final_tweets.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Successfully shown the dataset to the professor and he approved it . Now,i will start the Data Annotation process based on my annotation guidelines."
      ],
      "metadata": {
        "id": "h61qqc3ssNOK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Kz8wFO5cC6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y87hIt0IcC9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skGIAAbScDAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScXghEUacDC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x-KvEfG1cDGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}